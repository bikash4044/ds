{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values.\n",
    "\n",
    "Ans:  \n",
    "\n",
    "Missing values refer to the absence of data for one or more attributes in a dataset. They can occur due to various reasons such as errors in data collection, data corruption, or non-responsiveness in surveys.\n",
    "\n",
    "Handling missing values is crucial because many machine learning algorithms and statistical methods cannot process datasets with incomplete data directly. Missing values can lead to biased estimates, reduce the accuracy of the model, and skew results, compromising the validity of any analysis performed. Ignoring missing values or handling them poorly can result in models that do not generalize well to new data, leading to incorrect predictions and potentially flawed decision-making. By addressing missing values appropriately, we ensure the integrity of the dataset, improve model performance, and make our analyses more reliable.\n",
    "\n",
    "Algorithms Not Affected by Missing Values\n",
    "\n",
    "Decision Trees: Handle missing values by splitting nodes based on available data and using surrogate splits if needed.\n",
    "\n",
    "Random Forests: Aggregate predictions from multiple decision trees, each of which can handle missing values independently.\n",
    "\n",
    "Gradient Boosting Machines (GBM): Often includes mechanisms to handle missing data during training by using available data for splits.\n",
    "\n",
    "K-Nearest Neighbors (KNN): Estimates missing values using data from the nearest neighbors.\n",
    "\n",
    "Naive Bayes: Can be adapted to handle missing values by incorporating them into probability calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: List down techniques used to handle missing data. Give an example of each with python code.\n",
    "\n",
    "Ans: Each one is mentioned along with respective code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A\n",
      "0  1.0\n",
      "1  2.0\n",
      "2  3.0\n",
      "3  4.0\n",
      "4  5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bikas\\AppData\\Local\\Temp\\ipykernel_11400\\1546064519.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['A'].fillna(df['A'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4, 5]})\n",
    "\n",
    "# Mean Imputation: Replace missing values with the mean of the column\n",
    "df['A'].fillna(df['A'].mean(), inplace=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A\n",
      "0  1.0\n",
      "1  2.0\n",
      "2  3.0\n",
      "3  4.0\n",
      "4  5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bikas\\AppData\\Local\\Temp\\ipykernel_11400\\4232191437.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['A'].fillna(df['A'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4, 5]})\n",
    "\n",
    "# Median Imputation: Replace missing values with the median of the column\n",
    "df['A'].fillna(df['A'].median(), inplace=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A\n",
      "0  1.0\n",
      "1  2.0\n",
      "2  2.0\n",
      "3  2.0\n",
      "4  5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bikas\\AppData\\Local\\Temp\\ipykernel_11400\\1890085867.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['A'].fillna(df['A'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'A': [1, 2, 2, np.nan, 5]})\n",
    "\n",
    "# Mode Imputation: Replace missing values with the mode of the column\n",
    "df['A'].fillna(df['A'].mode()[0], inplace=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A\n",
      "0  1.0\n",
      "1  1.0\n",
      "2  1.0\n",
      "3  4.0\n",
      "4  5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bikas\\AppData\\Local\\Temp\\ipykernel_11400\\167215876.py:8: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'A': [1, np.nan, np.nan, 4, 5]})\n",
    "\n",
    "# Forward Fill: Fill missing values using the last available observation\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A\n",
      "0  1.0\n",
      "1  4.0\n",
      "2  4.0\n",
      "3  4.0\n",
      "4  5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bikas\\AppData\\Local\\Temp\\ipykernel_11400\\1844074812.py:8: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'A': [1, np.nan, np.nan, 4, 5]})\n",
    "\n",
    "# Backward Fill: Fill missing values using the next available observation\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A\n",
      "0  1.0\n",
      "1  2.0\n",
      "2  3.0\n",
      "3  4.0\n",
      "4  5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'A': [1, np.nan, 3, np.nan, 5]})\n",
    "\n",
    "# Interpolation: Estimate missing values based on other values in the column\n",
    "df['A'] = df['A'].interpolate()\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after dropping rows:\n",
      "      A    B\n",
      "1  2.0  2.0\n",
      "3  4.0  4.0\n",
      "4  5.0  5.0\n",
      "DataFrame after dropping columns:\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4, 5], 'B': [np.nan, 2, 3, 4, 5]})\n",
    "\n",
    "# Drop Missing Values:\n",
    "# Drop rows with any missing values\n",
    "df_dropped_rows = df.dropna()\n",
    "\n",
    "# Drop columns with any missing values\n",
    "df_dropped_columns = df.dropna(axis=1)\n",
    "\n",
    "print(\"DataFrame after dropping rows:\\n\", df_dropped_rows)\n",
    "print(\"DataFrame after dropping columns:\\n\", df_dropped_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  1.0\n",
      "1  2.0  2.5\n",
      "2  2.5  3.0\n",
      "3  4.0  4.0\n",
      "4  5.0  5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4, 5], 'B': [1, np.nan, 3, 4, 5]})\n",
    "\n",
    "# Predictive Imputation: Use KNN to impute missing values\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "print(df_imputed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
    "\n",
    "Ans:\n",
    "\n",
    " Imbalanced data refers to a dataset where the distribution of classes or outcomes is not uniform. Specifically, in classification tasks, this means that one class significantly outnumbers the others.\n",
    "\n",
    "If imbalanced data is not handled, the model may become biased towards the majority class, leading to misleading performance metrics, poor generalization, and inadequate prediction of the minority class. Addressing data imbalance is crucial to ensure the model performs well across all classes and provides reliable predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-sampling are required.\n",
    "\n",
    "Ans:\n",
    "\n",
    "Up-sampling\n",
    "\n",
    "Definition: Up-sampling involves increasing the number of instances in the minority class to balance the dataset. This is typically done by duplicating existing instances or generating synthetic examples.\n",
    "\n",
    "When Required: Up-sampling is required when the dataset has a significant imbalance, with the minority class having much fewer instances compared to the majority class. This helps ensure that the model learns to recognize the minority class more effectively.\n",
    "\n",
    "Down-sampling\n",
    "\n",
    "Definition: Down-sampling involves reducing the number of instances in the majority class to balance the dataset. This is done by randomly removing instances from the majority class.\n",
    "\n",
    "When Required: Down-sampling is required when the dataset has a large imbalance with the majority class having far more instances than the minority class. This helps prevent the model from being biased towards the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: What is data Augmentation? Explain SMOTE.\n",
    "\n",
    "Ans:\n",
    "\n",
    "Data augmentation is a technique used to increase the diversity of a training dataset without collecting new data. It involves creating new examples from the existing data by applying various transformations or generating synthetic samples. This is particularly useful in scenarios where acquiring more data is expensive or impractical.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a method used to address class imbalance by generating synthetic examples for the minority class. It works by selecting instances from the minority class and creating new samples along the line segments connecting these instances to their nearest neighbors. This interpolation helps to augment the minority class, balancing the dataset and allowing the model to better learn the characteristics of the minority class, thereby improving overall classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
    "\n",
    "Ans:\n",
    "\n",
    "\n",
    "Outliers are data points that significantly deviate from the majority of the data in a dataset, often due to errors, variability, or unique conditions. It is essential to handle outliers because they can skew statistical measures like the mean and variance, distort model performance by affecting algorithms sensitive to data scales, and potentially indicate data quality issues that need addressing. Properly managing outliers ensures more accurate analysis and reliable model outcomes, preventing misleading results and maintaining the integrity of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
    "\n",
    "Ans:\n",
    "\n",
    "1. Mean Imputation\n",
    "2. Median Imputation\n",
    "3. Mode Imputation\n",
    "4. Forward Fill\n",
    "5. Backward Fill\n",
    "6. Interpolation\n",
    "7. Drop Missing Values\n",
    "8. Predictive Imputation\n",
    "9. Using Algorithms that Handle Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?\n",
    "\n",
    "Ans:\n",
    "\n",
    "1. Descriptive Statistics Analysis\n",
    "2. Missing Data Patterns Visualization\n",
    "3. Correlation Analysis\n",
    "4. Chi-Square Test for Missing Data Patterns\n",
    "5. Little's MCAR Test\n",
    "6. Comparing Distributions of Missing vs. Non-Missing Data\n",
    "7. Data Imputation with and without Missing Data Patterns\n",
    "8. Statistical Tests for Missing Data Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n",
    "\n",
    "Ans:\n",
    "\n",
    "1. Confusion Matrix Analysis\n",
    "2. Precision, Recall, and F1-Score\n",
    "3. ROC Curve and AUC (Area Under the Curve)\n",
    "4. PR Curve (Precision-Recall Curve)\n",
    "5. Cross-Validation with Stratified Sampling\n",
    "6. Resampling Techniques (Up-sampling and Down-sampling)\n",
    "7. Using Different Evaluation Metrics (e.g., Matthews Correlation Coefficient)\n",
    "8. Cost-sensitive Learning\n",
    "9. Model Calibration and Threshold Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?\n",
    "\n",
    "Ans:\n",
    "\n",
    "1. Random Undersampling\n",
    "2. Tomek Links\n",
    "3. Edited Nearest Neighbors (ENN)\n",
    "4. NearMiss\n",
    "5. Cluster Centroids\n",
    "6. Tomek Links with Edited Nearest Neighbors\n",
    "7. Synthetic Data Generation (e.g., SMOTE for minority class and Down-sampling for majority class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?\n",
    "\n",
    "Ans:\n",
    "\n",
    "1. SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "2. ADASYN (Adaptive Synthetic Sampling)\n",
    "3. Random Oversampling\n",
    "4. Borderline-SMOTE\n",
    "5. KMeans-SMOTE\n",
    "6. SMOTE-NC (SMOTE for Nominal and Continuous features)\n",
    "7. Combination of Over-sampling and Under-sampling (e.g., SMOTE + Tomek Links)\n",
    "8. Generative Adversarial Networks (GANs) for synthetic data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
