{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is the KNN algorithm?\n",
    "\n",
    "Ans:\n",
    "\n",
    "The K-Nearest Neighbors (KNN) algorithm classifies data points based on the majority class among their k-nearest neighbors in the feature space. For regression, it predicts the value based on the average of the k-nearest neighbors' values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. How do you choose the value of K in KNN?\n",
    "\n",
    "Ans:\n",
    "\n",
    "- Cross-Validation: Test different values of K and select the one with the best performance.\n",
    "- Odd Numbers: For classification, use odd values to avoid ties.\n",
    "- Domain Knowledge: Consider problem specifics if applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. What is the difference between KNN classifier and KNN regressor?\n",
    "\n",
    "Ans:\n",
    "\n",
    "KNN Classifier: Predicts the class label based on the majority vote of the k-nearest neighbors.\n",
    "KNN Regressor: Predicts a continuous value based on the average of the k-nearest neighbors' values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. How do you measure the performance of KNN?\n",
    "\n",
    "Ans:\n",
    "\n",
    "For Classification: Use accuracy, precision, recall, F1 score, or confusion matrix.\n",
    "For Regression: Use metrics like Mean Squared Error (MSE), Mean Absolute Error (MAE), or R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. What is the curse of dimensionality in KNN?\n",
    "\n",
    "Ans:\n",
    "\n",
    "The curse of dimensionality refers to the problem where increasing the number of features (dimensions) makes distance metrics less effective, leading to poor performance and increased computational cost in KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. How do you handle missing values in KNN?\n",
    "\n",
    "Ans:\n",
    "\n",
    "Imputation: Fill in missing values using mean, median, or mode.\n",
    "Removing: Exclude instances with missing values.\n",
    "Weighted Distance: Adjust distance calculations to account for missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for which type of problem?\n",
    "\n",
    "Ans:\n",
    "\n",
    "KNN Classifier: Best for categorical classification tasks. Performs well with small to medium-sized datasets and clear class boundaries.\n",
    "KNN Regressor: Best for predicting continuous values. Suitable for regression tasks where relationships between variables are complex but relatively straightforward.\n",
    "Comparison:\n",
    "\n",
    "Classifier: Evaluated using classification metrics (accuracy, precision).\n",
    "Regressor: Evaluated using regression metrics (MSE, MAE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks, and how can these be addressed?\n",
    "\n",
    "Ans:\n",
    "\n",
    "\n",
    "Strengths:\n",
    "\n",
    "KNN Classifier: Simple, intuitive, no training phase.\n",
    "KNN Regressor: Easy to understand, effective for small datasets.\n",
    "\n",
    "Weaknesses:\n",
    "\n",
    "KNN Classifier: Sensitive to irrelevant features, high computational cost with large datasets, and poor performance with high dimensionality.\n",
    "KNN Regressor: Sensitive to noisy data, performance can degrade with large feature sets.\n",
    "\n",
    "Addressing Weaknesses:\n",
    "\n",
    "Feature Selection: Reduce dimensionality and remove irrelevant features.\n",
    "Distance Metrics: Use appropriate distance measures.\n",
    "Data Scaling: Normalize or standardize features.\n",
    "Optimization: Use KD-trees or Ball-trees for faster searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?\n",
    "\n",
    "Ans:\n",
    "\n",
    "Euclidean Distance: Measures the straight-line distance between two points in a multi-dimensional space. It’s calculated as the square root of the sum of squared differences.\n",
    "\n",
    "Manhattan Distance: Measures the distance between two points by summing the absolute differences of their coordinates. It’s also known as L1 distance or taxicab distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. What is the role of feature scaling in KNN?\n",
    "\n",
    "Ans:\n",
    "\n",
    "Feature scaling ensures all features contribute equally to distance calculations. It prevents features with larger scales from dominating the distance metric, improving KNN performance and accuracy."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
