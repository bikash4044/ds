{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application.\n",
    "\n",
    "Ans:\n",
    "\n",
    "Min-Max scaling, or normalization, transforms feature values to a fixed range, usually [0, 1]. The formula is:\n",
    "\n",
    "X scaled = (X - X min)/(X max - X min)\n",
    "\n",
    "where:\n",
    "\n",
    "X is the original feature value\n",
    "X_min is the minimum value of the feature\n",
    "X_max is the maximum value of the feature\n",
    "\n",
    "Example\n",
    "\n",
    "Suppose you have house sizes in square feet as follows:\n",
    "\n",
    "House 1: 800 sq ft\n",
    "House 2: 1200 sq ft\n",
    "House 3: 2000 sq ft\n",
    "Identify Minimum and Maximum Values:\n",
    "\n",
    "Minimum value: 800 sq ft\n",
    "Maximum value: 2000 sq ft\n",
    "Apply Min-Max Scaling:\n",
    "\n",
    "For House 1:\n",
    "(800 - 800) / (2000 - 800) = 0\n",
    "For House 2:\n",
    "(1200 - 800) / (2000 - 800) = 0.33\n",
    "For House 3:\n",
    "(2000 - 800) / (2000 - 800) = 1\n",
    "Scaled Values:\n",
    "\n",
    "House 1: 0\n",
    "House 2: 0.33\n",
    "House 3: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application.\n",
    "\n",
    "Ans:\n",
    "\n",
    "Unit Vector Technique in Feature Scaling\n",
    "\n",
    "The Unit Vector technique, also known as normalization, scales feature values so that the length (or norm) of the feature vector is 1. Each feature value is divided by the Euclidean norm of the feature vector.\n",
    "\n",
    "Formula: For a feature vector X, the unit vector normalization is:\n",
    "\n",
    "X_normalized = X / ||X||\n",
    "\n",
    "where ||X|| is the Euclidean norm (or L2 norm) of the vector X, calculated as:\n",
    "\n",
    "||X|| = sqrt(sum(X_i^2))\n",
    "\n",
    "Differences from Min-Max Scaling\n",
    "\n",
    "Range of Values:\n",
    "\n",
    "Unit Vector: Scales feature values so the length of the vector is 1, but values are not constrained to a specific range like [0, 1].\n",
    "Min-Max Scaling: Transforms feature values to a fixed range, typically [0, 1], based on the minimum and maximum values.\n",
    "\n",
    "\n",
    "Normalization Type:\n",
    "\n",
    "Unit Vector: Normalizes the entire feature vector to have a unit norm, affecting the relative scale of values within the vector.\n",
    "Min-Max Scaling: Scales individual values based on their minimum and maximum, preserving relative spacing within a defined range.\n",
    "\n",
    "Example\n",
    "Suppose you have house sizes in square feet:\n",
    "\n",
    "House 1: 800 sq ft\n",
    "House 2: 1200 sq ft\n",
    "House 3: 2000 sq ft\n",
    "Calculate the Euclidean Norm of the Vector:\n",
    "\n",
    "Compute the norm:\n",
    "||X|| = sqrt(800^2 + 1200^2 + 2000^2)\n",
    "||X|| = sqrt(640000 + 1440000 + 4000000)\n",
    "||X|| = sqrt(6080000) approx 2465.0\n",
    "Normalize Each Feature Value:\n",
    "\n",
    "For House 1:\n",
    "X_normalized_1 = 800 / 2465.0 approx 0.325\n",
    "For House 2:\n",
    "X_normalized_2 = 1200 / 2465.0 approx 0.487\n",
    "For House 3:\n",
    "X_normalized_3 = 2000 / 2465.0 approx 0.812\n",
    "Normalized Values:\n",
    "\n",
    "House 1: 0.325\n",
    "House 2: 0.487\n",
    "House 3: 0.812"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application.\n",
    "\n",
    "Ans:\n",
    "\n",
    "PCA is a technique that reduces the dimensionality of data by transforming it into a new set of variables (principal components) that capture the most variance.\n",
    "\n",
    "How PCA Works:\n",
    "\n",
    "- Standardize the Data: Center and scale the data.\n",
    "- Compute Covariance Matrix: Analyze how features vary with each other.\n",
    "- Calculate Eigenvalues and Eigenvectors: Identify the principal components.\n",
    "- Select Principal Components: Choose the top components based on eigenvalues.\n",
    "- Transform the Data: Project the original data onto these components.\n",
    "\n",
    "Example\n",
    "\n",
    "Data: Heights (170 cm, 180 cm, 160 cm) and Weights (60 kg, 80 kg, 55 kg).\n",
    "\n",
    "1. Standardize the Data: Normalize heights and weights.\n",
    "1. Compute Covariance Matrix: Determine relationships between height and weight.\n",
    "1. Calculate Eigenvalues and Eigenvectors: Find principal components.\n",
    "1. Select Principal Component: Choose the one with the highest variance.\n",
    "1. Transform Data: Reduce data to this principal component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept.\n",
    "\n",
    "Ans:\n",
    "\n",
    "PCA is a feature extraction technique that transforms original features into a new set of features (principal components) that capture the most variance in the data. It simplifies data by reducing dimensionality while retaining essential information.\n",
    "\n",
    "How Can PCA Be Used for Feature Extraction:\n",
    "\n",
    "Transform Original Features: Convert original features into principal components.\n",
    "\n",
    "Select Principal Components: Choose components that capture the most variance.\n",
    "Reduce Dimensionality: Use the selected components as new features.\n",
    "\n",
    "Example\n",
    "\n",
    "Original Data: Three features (A, B, C).\n",
    "\n",
    "- Standardize Data: Normalize features A, B, and C.\n",
    "- Compute Covariance Matrix: Analyze feature relationships.\n",
    "- Calculate Eigenvalues and Eigenvectors: Determine principal components.\n",
    "- Select Principal Components: Choose the top components, e.g., the first two.\n",
    "- Transform Data: Project data onto these two components, reducing dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset.\n",
    "\n",
    "Ans:\n",
    "\n",
    "Identify Minimum and Maximum Values:\n",
    "\n",
    "Determine the minimum and maximum values for each feature (price, rating, delivery time).\n",
    "Apply Min-Max Scaling Formula:\n",
    "\n",
    "Use the formula: X_scaled = (X - X_min) / (X_max - X_min)\n",
    "Here, X is the original value, X_min is the minimum value, and X_max is the maximum value for that feature.\n",
    "Transform Each Feature:\n",
    "\n",
    "Price: Scale all price values to [0, 1].\n",
    "Rating: Scale all rating values to [0, 1].\n",
    "Delivery Time: Scale all delivery time values to [0, 1].\n",
    "Use Scaled Data:\n",
    "\n",
    "Replace original feature values with their scaled values to ensure equal contribution of each feature to the recommendation system.\n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "- Price: $10 (min), $50 (max)\n",
    "- Rating: 3 (min), 5 (max)\n",
    "- Delivery Time: 15 minutes (min), 60 minutes (max)\n",
    "- Scaling Calculation:\n",
    "- - For a price of $30: (30 - 10) / (50 - 10) = 0.5\n",
    "- - For a rating of 4: (4 - 3) / (5 - 3) = 0.5\n",
    "- - For a delivery time of 30 minutes: (30 - 15) / (60 - 15) = 0.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.         -0.57894737 -0.05263158  0.47368421  1.        ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([1, 5, 10, 15, 20])\n",
    "\n",
    "data_min = np.min(data)\n",
    "data_max = np.max(data)\n",
    "\n",
    "new_min = -1\n",
    "new_max = 1\n",
    "\n",
    "scaled_data = new_min + (data - data_min) * (new_max - new_min) / (data_max - data_min)\n",
    "\n",
    "print(scaled_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
    "\n",
    "Ans:\n",
    "\n",
    "To perform feature extraction using PCA on a dataset with features like [height, weight, age, gender, blood pressure], follow these steps:\n",
    "\n",
    "Standardize the Data:\n",
    "\n",
    "Standardize each feature to have zero mean and unit variance, especially important if features are on different scales.\n",
    "\n",
    "Compute the Covariance Matrix:\n",
    "\n",
    "Calculate the covariance matrix to understand how features vary with each other.\n",
    "\n",
    "Calculate Eigenvalues and Eigenvectors:\n",
    "\n",
    "Find the eigenvalues and eigenvectors of the covariance matrix. Eigenvectors represent the directions of maximum variance, and eigenvalues represent the magnitude of variance in those directions.\n",
    "\n",
    "Sort and Select Principal Components:\n",
    "\n",
    "Sort the eigenvectors by their corresponding eigenvalues in descending order.\n",
    "Choose the top principal components based on the amount of variance they explain.\n",
    "\n",
    "Determine the Number of Principal Components to Retain:\n",
    "\n",
    "Cumulative Explained Variance: Compute the cumulative explained variance ratio for the principal components.\n",
    "\n",
    "Choose Components: Retain enough principal components to cover a significant percentage of the total variance, typically 90% to 95%.\n",
    "\n",
    "Example\n",
    "\n",
    "Assuming the explained variance ratios for the principal components are:\n",
    "\n",
    "- Principal Component 1: 40% variance\n",
    "- Principal Component 2: 25% variance\n",
    "- Principal Component 3: 15% variance\n",
    "- Principal Component 4: 10% variance\n",
    "- Principal Component 5: 10% variance\n",
    "\n",
    "Steps to Choose Principal Components:\n",
    "\n",
    "Calculate Cumulative Explained Variance:\n",
    "\n",
    "- PC1 + PC2 = 40% + 25% = 65%\n",
    "- PC1 + PC2 + PC3 = 65% + 15% = 80%\n",
    "- PC1 + PC2 + PC3 + PC4 = 80% + 10% = 90%\n",
    "- PC1 + PC2 + PC3 + PC4 + PC5 = 100%\n",
    "\n",
    "Select Components:\n",
    "\n",
    "To retain at least 90% of the variance, I would choose the first 4 principal components."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
